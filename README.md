## Overview

| Developed by | Guardrails AI |
| --- | --- |
| Date of development | Feb 15, 2024 |
| Validator type | Brand risk, QA, chatbots |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

## Description

This validator ensures that no competitors for an organization are being named. In order to use this validator, you need to provide a list of competitors that you donâ€™t want to name.

### Resources required

- Dependencies: `nltk`

## Installation

```bash
$ guardrails hub install hub://guardrails/competitor_check
```

## Usage Examples

### Validating string output via Python

In this example, we apply the validator to a string output generated by an LLM.

```python
# Import Guard and Validator
from guardrails.hub import CompetitorCheck

# Initialize Validator
val = CompetitorCheck(
    competitors=["Apple", "Samsung",]
    on_fail="noop"
)

# Setup Guard
guard = Guard.from_string(
    validators=[val, ...],
)

guard.parse("The apple doesn't fall far from the tree.")  # Validator passes
guard.parse("Apple just released a new iPhone.")  # Validator fails
```

### Validating JSON output via Python

In this example, we apply the validator to a string that is a field within a Pydantic object.

```python
# Import Guard and Validator
from pydantic import BaseModel
from guardrails.hub import CompetitorCheck
from guardrails import Guard

# Initialize Validator
val = CompetitorCheck(
    competitors=["Apple", "Samsung",]
    on_fail="noop"
)

# Create Pydantic BaseModel
class MarketingCopy(BaseModel):
    product_name: str
    product_description: str = Field(
        description="Description about the product", validators=[val]
    )

# Create a Guard to check for valid Pydantic output
guard = Guard.from_pydantic(output_class=MarketingCopy)

# Run LLM output generating JSON through guard
guard.parse("""
{
    "product_name": "New Phone",
    "product_description": "We're excited to release a new phone."
}
""")
```

## API Reference

`__init__`
- `competitors`: List of names of competitors to avoid.
- `on_fail`: The policy to enact when the validator fails.
